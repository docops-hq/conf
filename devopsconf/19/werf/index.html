<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>werf — наш инструмент для CI/CD в Kubernetes &middot; Конспекты</title><link rel=stylesheet href=/conf/css/style.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700"><link rel=stylesheet href=/conf/custom.css><link rel=icon type=image/png sizes=32x32 href=/conf/images/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/conf/images/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/conf/images/apple-touch-icon.png><link href rel=alternate type=application/rss+xml title=Конспекты><script async src="https://www.googletagmanager.com/gtag/js?id=UA-107215405-3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-107215405-3');</script></head><body><nav class=nav><div class=nav-container><a href=/conf/><h2 class=nav-title>Конспекты</h2></a><ul><li><a href=/conf/>Posts</a></li></ul></div></nav><main><div class=post><div class=single__header><div class=post-info>Дмитрий Столяров, Тимофей Кириллов, Алексей Игрычев, Иван Михейкин, компания Флант</div><h1 class=post-title>werf — наш инструмент для CI/CD в Kubernetes</h1><div class=post-line></div><div class=tag-block><span class=catalogue-tags><a href=/conf/tags/devopsconf class=tags>DevOpsConf</a></span><span class=catalogue-tags><a href=/conf/tags/2019 class=tags>2019</a></span></div></div><p>В первую очередь: сюда можно ставить звездочки <a href=https://github.com/flant/werf>github.com/flant/werf</a></p><h1 id=доставка>Доставка</h1><p>Доклад про то, как делать доставку в K8s.
Есть софт, его нужно доставить на продакшен.</p><p>Есть цикл непрерывных улучшений.
Разработка, тестирование, доставка, метрики, снова разработка&hellip;</p><p>В нашем случае софт — это докер, а продакшен — это k8s.
Пока в проде не было k8s, продакшен для докера был вообще непонятным.
А когда появился k8s, продакшен стал стандартизованным и с API.
Когда-то то же самое произошло с софтом: было как попало, стало в докере.</p><p>Как выглядит доставка:</p><ul><li>Есть гит с кодом приложения и кодом сборки,</li><li>мы собираем из этого докер-образ и пушим его в registry,</li><li>ещё в гите есть инструкции как выполнять приложение, мы их отправляем в k8s на тест и на прод.</li><li>И ещё там есть тесты, разные.</li><li>Наконец, есть CI-система, которая всё это выполняет.</li></ul><p>Immutable инфраструктура предполагает, что мы собираем образ, его тестируем и его же отправляем на прод.</p><p>Ещё важно, что инфраструктура — это код.
Как только мы это правило нарушаем, всё ломается.</p><p>Что такое delivery?
Это путь git -&gt; build -&gt; test -&gt; release -&gt; run.
Продукт доставлен только тогда, когда пользователь смог им воспользоваться.</p><p>У всей этой схемы на основе Git есть название: GitOps.
Давайте посмотрим на эту схему подробнее.</p><h1 id=сборка-build>Сборка (build)</h1><p>Вес образа имеет значение.
Если идти прямым путём, то получится очень большой образ.
А если использовать multistage, то гораздо меньше.</p><p><img src=../../../images/devopsconf/19/werf01.png alt=werf01></p><p>Ещё все знают, что много слоёв — это плохо, а хорошо делать так:</p><p><img src=../../../images/devopsconf/19/werf02.png alt=werf02></p><p>Однако, попробуйте-ка подебажить такую сборку.
Где оно упало внутри этого шага? Никто не знает.
Приходится вручную выполнять по одной строке.</p><p>Ещё код приложения меняется часто, а зависимости редко.
Поэтому приходится сначала добавлять <code>requirements.txt</code>, потом <code>pip install -r requirements.txt</code>,
и только потом добавлять оставшийся код приложения.</p><p><img src=../../../images/devopsconf/19/werf03.png alt=werf03></p><p>Ещё нередко из одного репозитория мы можем собирать много образов.
Мы можем сделать много докерфайлов или один докерфайл со stage&rsquo;ами,
и потом запускать сборку через shell-cкрипт.</p><p>И всё это только вершина айсберга!</p><ul><li>Есть ещё история с монтированием.</li><li>Например, мы хотим закешировать результат работы какого-то менеджера зависимостей.</li><li>Или мы хотим ssh и нам нужно пробросить сокет ssh-агента.</li><li>Или мы хотим собирать образы без shell, а хотим использовать Ansible.</li><li>Наконец, можно хотеть собирать образы вообще без Docker.
Так нам для сборки понадобится виртуальная машина, но у нас же уже есть k8s.
Однако, в нём докер, а в докере собирать докер-образы — это плохо.</li><li>Параллельная сборка. Тут параллельность можно понять кучей способов.</li><li>Распределенная сборка. Поды теряют кеши, с этим нужно что-то делать.</li><li>Автомагия!</li></ul><p>Чем решаются эти проблемы:</p><ul><li>moby/buildkit</li><li>Kaniko</li><li>Buildpacks.io</li><li>buildah</li><li>genuinetools/img</li></ul><p>Параллельно развивается куча альтернативных сборщиков.
Каждый из них решает часть задачи, а целиком — ни один.</p><p>Werf делают пять лет.
Сделанное отмечено синим, план к концу этого лета — жёлтым.</p><p><img src=../../../images/devopsconf/19/werf04.png alt=werf04></p><h1 id=публикация-в-registry-push>Публикация в registry (push)</h1><p>Вопрос: как тегировать образ?</p><p>Нужно гарантировать воспроизводимость.
У нас есть коммит в гите, он иммутабельный.
Мы хотим из него собрать образ и сохранить связь между ними.
Когда на проде работает приложение, мы хотим узнавать, из какого коммита оно собрано.</p><h2 id=git-tag>git tag</h2><p>Обычный путь такой:</p><ol><li>Поставили тег в гите</li><li>Собрали образ и поставили тот же тег на него</li><li>Протестировали</li><li>Выкатили на прод</li></ol><p>Тут есть проблемы:</p><ul><li>Порядок контринтуитивный. Мы сначала тегировали, а только потом тестируем.</li><li>Плохо сочетается с git flow.</li></ul><h2 id=git-commit-tag>git commit + tag</h2><p>Собираем и тестируем образы из коммитов.
Когда очередной коммит/образ прошёл все тесты и мы готовы выкатывать его на прод, ставим тег на уже собранный образ.</p><p>Ограничение: только fast-forward merging, не поддерживает мерж-коммиты.</p><h2 id=content-addressable>Content addressable</h2><p>Берём хеши исходных докер-образов, текст всех команд и хеши скопированных файлов.
Делаем из этого один хеш.
Он становится сигнатурой образа.
В список файлов можно не включать то, что не влияет на приложение, например changelog.</p><p>Плюс: сигнатура не меняется от мерж-коммитов.</p><p>Минус: нельзя точно восстановить, из какого коммита собран образ.
Это решается слоем с метаданными.</p><h1 id=очистка-registry>Очистка registry</h1><p>Рано или поздно место в registry заканчивается.
Если мы пушим новый образ с тем же тегом, какие-то слои устаревают, и registry с этим справляется.
Но есть и тегированные образы, которые больше не нужны.
Давайте будем их удалять.</p><p><img src=../../../images/devopsconf/19/werf05.png alt=werf05></p><p>Стратегии очистки:</p><ul><li>Не чистить.</li><li>Сделать полный сброс.
А после удаления нажать везде build.
Но тогда мы создадим много новых непротестированных образов.</li><li>Blue-green. Непонятно, когда удалять старый.</li><li>По времени. Тут мы либо слишком долго храним, либо удалим что-то нужное.</li><li>Вручную.</li></ul><p>Работоспособные варианты — не чистить вообще, либо сочетать blue-green с ручной очисткой.</p><p>Как эту задачу решает werf?</p><ol><li>Git head: собираем все ветки.
То, что протегировано в git, наверняка нужно в registry.</li><li>Что сейчас выкачено в k8s?</li><li>Что недавно было выкачено в k8s?</li><li>(в планах) анализируем Helm.</li></ol><p>Из всего этого получаем whitelist.
Всё, что не в нём — удаляем из registry.
Потом удаляем из кешей всё, на что не ссылаются существующие образы.</p><h1 id=деплой>Деплой</h1><h2 id=изменение-конфигураций>Изменение конфигураций</h2><p>Конфигурация для k8s лежит в гите.
В момент деплоя конфиг становится сильно больше.
В него добавляются:
* идентификаторы,
* служебная информация,
* значения по умолчанию,
* статус,
* admission webhook&rsquo;и,
* контроллеры всех видов и планировщик.</p><p>Получается, что в k8s находится некоторое живое проявление того, что было в гите.</p><p>Вот у нас новый коммит с новым конфигом.
Нельзя эту конфигурацию просто перезаписать.
Нужно сделать дифф между старой и новой и его накатить как патч на боевую версию.
Это называется «двухсторонний мерж» (2-way merge).
Так работает, например, Helm.</p><p><img src=../../../images/devopsconf/19/werf06.png alt=werf06></p><p>Можно делать иначе: между старой и новой версией смотреть, что удалено,
а между боевой и новой — что добавлено и изменено.</p><p><img src=../../../images/devopsconf/19/werf07.png alt=werf07></p><p>Вывод: декларативный подход не так прост.
Даже с декларативным описанием есть магия.
Но без декларативного подхода всё сильно хуже.</p><h2 id=применено-выкачено>Применено ≠ выкачено</h2><p>Представим, что у нас есть CI-система.
Она получает ивент и запускает деплой:</p><ol><li>Берёт шаблоны в YAML или JSON</li><li>Отдаёт их движку шаблонов</li><li>Получает отрендеренную конфигурацию</li><li>Применяет к ней изменения из боевой конфигурации k8s через 3-way merge.</li><li>Применяет результат обратно к k8s через API</li><li>K8s отвечает успехом CI-системе, а она отвечает пользователю.</li></ol><p>Применена новая конфигурация? Да. Выкачена? Нет.</p><p><img src=../../../images/devopsconf/19/werf08.png alt=werf08></p><p>K8s отвечает OK, когда получил новую конфигурацию.
Но применяется она не моментально.
Так работают Helm и kubectl.</p><p>А если pod не сможет рестартануть с новой конфигурацией?
«Пуля вылетела, проблемы на вашей стороне».</p><p><img src=../../../images/devopsconf/19/werf09.png alt=werf09></p><p>Поэтому нужен трекер, который следит за состоянием k8s.
Если k8s ответил OK, CI будет ждать трекера, который вернёт ОК только когда конфигурация успешно задеплоилась.</p><p>Подходящий инструмент — библиотека <a href=https://github.com/flant/kubedog>github.com/flant/kubedog</a>.
Этот трекер встроен в werf.</p><p>Главная аннотация — <code>fail-mode</code>. Три варианта:</p><ul><li>IgnoreAndContinueDeployProcess. Забей и продолжай деплой.</li><li>FailWholeDeployProcessImmediately. Падай сразу.</li><li>HopeUntilEndOfDeployProcess. Жди и надейся.</li></ul><p>Ещё важная аннотация: <code>failures-allowed-per-replica</code>.</p><p>Логи: <code>show-logs-until</code>.
Помогает собирать логи только до тех пор, когда pod готов.
Ошибки происходят до того, как он готов, и ошибки нам интересны.
А на готовый pod приходят задачи и в логах появляется куча шума, она нам неинтересна.</p><h2 id=что-мы-вообще-хотим-от-деплоя>Что мы вообще хотим от деплоя?</h2><ul><li>Надёжную декларативность.</li><li>Реальный статус.</li><li>Логи.</li><li>Прогресс. (Job висит — что происходит? Чего мы сейчас ждём?)</li><li>Автоматический откат. Выкат должен быть атомарным: или оно выкатилось до конца, или откатилось назад.</li></ul><h1 id=заключение>Заключение</h1><p>Всё сложнее, чем кажется с первого взгляда.
Дьявол кроется в деталях.</p><p>Любой софт — сырое и глючное гавно, пока им не начнут пользоваться.</p><p>Давайте вместе добьём эту тему, и пойдём дальше, решать другие вопросы.</p></div><div class=pagination><a href=/conf/highload/18/1.8-badoo-infradev/ class="left arrow">&#8592;</a>
<a href=/conf/highload/19/njs-nginx/ class="right arrow">&#8594;</a>
<a href=# class=top>Top</a></div></main><footer><span>&copy; <time datetime="2021-09-16 15:13:52.97355833 &#43;0000 UTC m=&#43;0.123205575">2021</time> . Made with <a href=https://gohugo.io>Hugo</a> using the <a href=https://github.com/EmielH/tale-hugo/>Tale</a> theme.</span></footer></body></html>